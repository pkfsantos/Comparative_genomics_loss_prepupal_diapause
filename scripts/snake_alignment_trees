#This script is to get nucleotide sequences for each orthogroup that will be used as input for the nucleotide and aminoacids  alignments using MACSE.
#The nucleotide alignments will be used to make gene trees

################Subset Orthogroups of interest####################
#First I filtered the table of Orthogroups.GeneCounts (output from orthfinder) to keep only orthogroups which 70% of the species were single-copy. 
#Those are my Orthogroups of interest for further analysis

##Keep orthogroups present in all spp (independent of the number or copies)
#awk -F "\t" '{for (i=2;i<=NF;++i) if ($i==0) next; print}' Orthogroups.GeneCount.tsv > Orthogroups_present_all_spp.tsv
##Keep orthogroups that are single-copy in 70 % of spp
#awk -F "\t" 'NR==1; {N=0.0; for (i=2; i<=NF;++i) if ($i>1) N++; if (N/(NF-1) < 0.3) print;}' Orthogroups_present_all_spp.tsv > Orthogroups_70_percent_single_copy.tsv
##get the first column (orthogroups ID) and exclude the first line (After awk command, I opened the file with nano e excluded 1st line)
#awk '{print $1}' Orthogroups_70_percent_single_copy.tsv > Orthogroups_Ids_interest.txt

#In the folder with all Orthogroup sequences, I used the Orthogroups_Ids_interest.txt file to subset the sequences

##Add .fa in the end of each line 
#sed -i 's/$/\.fa/' Orthogroups_Ids_interest.txt
##Create a directory for the subset files
#mkdir Orthogroups_of_interest
##Based on the list of Ids, copy the sequences to the new directory
#while IFS= read -r file; do cp "$file" Orthogroups_of_interest; done < Orthogroups_Ids_interest.txt
################END input files####################

#directory for longest isoforms
longiso_dir = "/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/longest_isoform/"
#directory with genomes and annotation
gen_annt_dir = "/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/genomes_annotation/"
#CDS nucleotide sequences directory
cdsnucl_dir = "/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/CDS_nucl/"
cdsnucl_rn = "/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/CDS_nucl/CDS_nucl_renamed/"
#directory for orthogroup sequences
ortho_seq_dir = "/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/CDS_aas/CDS_aas_renamed/OrthoFinder/Results_Dec12/Orthogroup_Sequences/Orthogroups_of_interest/"
#output directory for alignments
out = "/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/alignments/subset_spp/"
#output for duplication removal
out_dup = "/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/alignments/empty_outputs/"
#output for trees
out1 = "/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/trees/subset_spp/"

species_name, = glob_wildcards("/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/longest_isoform/{species}_longiso.gff")
orthog_name, = glob_wildcards("/uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/CDS_aas/CDS_aas_renamed/OrthoFinder/Results_Dec12/Orthogroup_Sequences/Orthogroups_of_interest/{orthogroup}.fa")
rule all:
     input:expand(cdsnucl_rn+"{name}.fasta", name=species_name), cdsnucl_rn+"All_CDS_nucl.fasta", expand(out+"{id}_nucl.fa", id=orthog_name), expand(out_dup+"{id}_output_alignment", id=orthog_name), expand(out_dup+"{id}_AA_NT_alignments", id=orthog_name)

#Get CDS nucleotide sequences using the genome and annotation
rule CDS_nucleotide:
     input: longiso_annotation = longiso_dir+"{name}_longiso.gff"
     output: cdsnucl_rn+"{name}.fasta"
     resources: mem_mb = 21000
     params: cpu = 7,
             fasta = gen_annt_dir+"{name}.fna",
             prefix = cdsnucl_dir+"{name}_CDS_nucl.fasta",
             id = "{name}"
     shell:"""
           module load agat/0.9.2
           agat_sp_extract_sequences.pl -g {input.longiso_annotation} -f {params.fasta} -t cds --roo --clean_final_stop -o {params.prefix}
#add the respective species name at the beginning of each sequence
           sed 's/>/>{params.id}_/g' /uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/CDS_nucl/{params.id}_CDS_nucl.fasta > {output}
           """

#Create a CDS nucleotide database
rule CDS_database:
     input: cdsnucl_rn
     output: cdsnucl_rn+"All_CDS_nucl.fasta"
     resources:mem_mb = 3000
     params:cpu=1,
            dir = cdsnucl_rn
     shell:"""
          cat {input}/*.fasta > {params.dir}/All_CDS_nucl.fasta
          """

#get fasta sequence based on ID
rule nucl_alignments:
     input: ortho_seq_dir+"{id}.fa"
     output:out+"{id}_nucl.fa"
     resources:mem_mb = 3000
     params:cpu=1,
            id = "{id}",
            out_align = out,
            nucl_fasta = cdsnucl_rn+"All_CDS_nucl.fasta"
     shell:"""
          module load python
          grep ">" {input} > {params.out_align}/{params.id}_fasta_header 
          sed 's/transcript_/transcript:/g;s/WGS_/WGS:/g' {params.out_align}/{params.id}_fasta_header > {params.out_align}/{params.id}_renamed
          python /uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/work/fastafetcher.py -f {params.nucl_fasta} -k {params.out_align}/{params.id}_renamed -o {output}
          """

#remove all paralogs sequences from the same species
rule remove_dupl:
     input: out+"{id}_nucl.fa"
     output:out_dup+"{id}_output_alignment"
     resources:mem_mb = 3000
     params:cpu=1,
            id = "{id}",
            out_align = out
     shell:"""
          module load R
#rename all fasta sequences to be only the spp name 
          sed 's/_[^_]*//2g' {input} > {params.out_align}/{params.id}_nucl_renamed.fa
          Rscript remove_species_w_dups.R {params.out_align}/{params.id}_nucl_renamed.fa
          touch {output}
          """

#get alignments
rule alignments:
     input: out_dup+"{id}_output_alignment"
     output:out_dup+"{id}_AA_NT_alignments"
     resources:mem_mb = 24000
     params:cpu=8,
            id = "{id}",
            out_align = out
     shell:"""
          module load singularity
          #for f in *_nucl_renamed.fa_dup_removed.fa; do mv "$f" "$.fa"; done
          cd /uufs/chpc.utah.edu/common/home/kapheim-group2/priscila/diapause_signatures/alignments/subset_spp
          singularity run $HOME/MACSE_ALFIX_v01.sif --in_seq_file {params.id}_nucl_renamed.fa_dup_removed.fa --java_mem 20000m --out_dir macse_output --out_file_prefix {params.id}
          touch {output}
          """
